{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.10.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "\n",
    "import random\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "grid_size = 5  # Grid size for player and enemies (positions range from 0 to 4)\n",
    "num_enemies = 4  # Number of enemies\n",
    "visited_states = 2  # Visited status can be 0 or 1\n",
    "wall_states = 2  # Wall status can be 0 (no wall) or 1 (wall)\n",
    "\n",
    "movements = np.array([\n",
    "    [0, 1],   # Move up\n",
    "    [1, 0],   # Move right\n",
    "    [-1, 0],  # Move left\n",
    "    [0, -1]   # Move down\n",
    "])\n",
    "\n",
    "# Generate walls: 0 for no wall, 1 for wall\n",
    "\n",
    "state_action_log = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Shape: (2, 2, 5, 5, 5, 5, 5, 5, 5, 5, 2)\n",
      "Estimated Value Grid Shape: (2, 2, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "Reward States Shape: (5, 5)\n"
     ]
    }
   ],
   "source": [
    "base_shape = [ visited_states, wall_states]\n",
    "enemy_shape = [grid_size, grid_size] * num_enemies  # Each enemy has x and y positions\n",
    "full_shape = base_shape + enemy_shape\n",
    "\n",
    "# # Generate estimated_value_grid filled with zeros\n",
    "estimated_value_grid = np.zeros(full_shape, dtype=float)\n",
    "\n",
    "# # Generate random indices into the movements array\n",
    "policy_indices = np.random.randint(0, 4, size=full_shape)\n",
    "\n",
    "# # Create the policy array by indexing into movements\n",
    "policy = movements[policy_indices]\n",
    "\n",
    "# # Now, policy has shape full_shape + (2,), where the last dimension stores (dx, dy)\n",
    "print(\"Policy Shape:\", policy.shape)  # For verification\n",
    "\n",
    "# # Generate reward_states: 40x40 grid of random 1s and 2s\n",
    "reward_states = np.random.choice([1, 2], size=(grid_size, grid_size))\n",
    "\n",
    "# # Output shapes for verification\n",
    "print(\"Estimated Value Grid Shape:\", estimated_value_grid.shape)\n",
    "print(\"Reward States Shape:\", reward_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = {}\n",
    "estimated_value_grid={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_maze_optimized(maze, s):\n",
    "    x, y = s\n",
    "    rows, cols = len(maze), len(maze[0])\n",
    "    half_grid = 5 // 2\n",
    "\n",
    "    partition = [\n",
    "        [\n",
    "            maze[(x + dx) % rows][(y + dy) % cols]\n",
    "            for dy in range(-half_grid, half_grid + 1)\n",
    "        ]\n",
    "        for dx in range(-half_grid, half_grid + 1)\n",
    "    ]\n",
    "    return np.array(partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimized_relative_positions(maze_size, player_pos, enemy_positions, grid_size=5):\n",
    "    x, y = player_pos\n",
    "    rows, cols = maze_size  # Maze dimensions\n",
    "    half_grid = grid_size // 2\n",
    "\n",
    "    relative_positions = []\n",
    "\n",
    "    for ex, ey in enemy_positions:\n",
    "        # Compute differences considering wrap-around\n",
    "        dx = (ex - x + cols) % cols\n",
    "        if dx > cols // 2:\n",
    "            dx -= cols\n",
    "\n",
    "        dy = (ey - y + rows) % rows\n",
    "        if dy > rows // 2:\n",
    "            dy -= rows\n",
    "\n",
    "        # Check if enemy is within the local grid\n",
    "        if -half_grid <= dx <= half_grid and -half_grid <= dy <= half_grid:\n",
    "            # Map to local grid coordinates (0 to 4)\n",
    "            local_x = int(dx + half_grid)\n",
    "            local_y = int(dy + half_grid)\n",
    "            relative_positions.append((local_x, local_y))\n",
    "    return relative_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_collision(current_state, enemies):\n",
    "    x, y = current_state\n",
    "    for enemy in enemies:\n",
    "        ex, ey = enemy[\"pos\"]\n",
    "        if (x, y) == (ex, ey):\n",
    "            return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_wall_ahead(current_state, action, reward_maze):\n",
    "    x, y = current_state\n",
    "    dx, dy = action\n",
    "    maze_rows, maze_cols = len(reward_maze),len(reward_maze[0])\n",
    "    nextx, nexty = (x + dx) % maze_rows, (y + dy) % maze_cols\n",
    "    return reward_maze[nextx][nexty] == 1  # Returns True if the next cell is a wall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_actions(current_state, reward_maze):\n",
    "    x, y = current_state\n",
    "    maze_rows, maze_cols = len(reward_maze),len(reward_maze[0])\n",
    "    valid_actions = []\n",
    "    for dx, dy in movements:\n",
    "        nextx, nexty = (x + dx) % maze_rows, (y + dy) % maze_cols\n",
    "        if reward_maze[nextx][nexty] != 1:  # Not a wall\n",
    "            valid_actions.append((dx, dy))\n",
    "    return valid_actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Policy_Update():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Next_action(current_state, policy, enemies, reward_maze, grid_size=5):\n",
    "    maze_rows, maze_cols = len(reward_maze),len(reward_maze[0])\n",
    "    x, y = current_state\n",
    "\n",
    "    # Retrieve enemy positions and compute relative positions\n",
    "    og_enemy_positions = [enemy[\"pos\"] for enemy in enemies]\n",
    "    enemy_positions = optimized_relative_positions(\n",
    "        (maze_rows, maze_cols), current_state, og_enemy_positions, grid_size=grid_size\n",
    "    )\n",
    "\n",
    "    # Get food and wall status at the current position\n",
    "    food = int(reward_maze[x][y] == 2)\n",
    "    wall = int(reward_maze[x][y] == 1)\n",
    "\n",
    "    # Prepare enemy positions for the state index\n",
    "    max_enemies_in_local_grid = len(enemy_positions)\n",
    "    enemy_positions.sort()\n",
    "    padded_enemy_positions = enemy_positions[:max_enemies_in_local_grid]\n",
    "    num_missing = max_enemies_in_local_grid - len(padded_enemy_positions)\n",
    "    padded_enemy_positions.extend([(-1, -1)] * num_missing)  # Use placeholder (-1, -1)\n",
    "\n",
    "    # Flatten the enemy positions list\n",
    "    enemy_positions_flat = [coord for pos in padded_enemy_positions for coord in pos]\n",
    "\n",
    "    # Build the state index tuple\n",
    "    indices_s = (food, wall) + tuple(enemy_positions_flat)\n",
    "\n",
    "    # Retrieve the action from the policy dictionary\n",
    "    action = policy.get(indices_s)\n",
    "\n",
    "    # If action is None or leads into a wall, select a valid action\n",
    "    if action is None or is_wall_ahead(current_state, action, reward_maze):\n",
    "        valid_actions = get_valid_actions(current_state, reward_maze)\n",
    "        if valid_actions:\n",
    "            action = random.choice(valid_actions)\n",
    "        else:\n",
    "            action = (0, 0)  # No valid moves, stay in place\n",
    "\n",
    "    # Append the state index, action, reward value, and current state to the log\n",
    "    state_action_log.append((indices_s, action, reward_maze[x][y], current_state))\n",
    "\n",
    "    return action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_policy(old_indices_s,policy, prev_player_pos,estimated_value_grid, og_enemy_positions, reward_maze):\n",
    "    maze_rows, maze_cols = len(reward_maze),len(reward_maze[0])\n",
    "    x,y=prev_player_pos\n",
    "    e1=optimized_relative_positions(\n",
    "        (maze_rows, maze_cols), ((x+1)%maze_rows,y), og_enemy_positions, grid_size=grid_size\n",
    "    )\n",
    "    f1 = int(reward_maze[(x+1)%maze_rows][y] == 2)\n",
    "    w1 = int(reward_maze[(x+1)%maze_rows][y] == 1)\n",
    "    max_enemies_in_local_grid = len(e1)\n",
    "    e1.sort()\n",
    "    padded_enemy_positions = e1[:max_enemies_in_local_grid]\n",
    "    num_missing = max_enemies_in_local_grid - len(padded_enemy_positions)\n",
    "    padded_enemy_positions.extend([(-1, -1)] * num_missing)\n",
    "    enemy_positions_flat = [coord for pos in padded_enemy_positions for coord in pos]\n",
    "    indices_1 = (f1, w1) + tuple(enemy_positions_flat)\n",
    "    e2=optimized_relative_positions(\n",
    "        (maze_rows, maze_cols), ((x-1)%maze_rows,y), og_enemy_positions, grid_size=grid_size\n",
    "    )\n",
    "    f2 = int(reward_maze[(x-1)%maze_rows][y] == 2)\n",
    "    w2 = int(reward_maze[(x-1)%maze_rows][y] == 1)\n",
    "    max_enemies_in_local_grid = len(e2)\n",
    "    e2.sort()\n",
    "    padded_enemy_positions = e2[:max_enemies_in_local_grid]\n",
    "    num_missing = max_enemies_in_local_grid - len(padded_enemy_positions)\n",
    "    padded_enemy_positions.extend([(-1, -1)] * num_missing)\n",
    "    enemy_positions_flat = [coord for pos in padded_enemy_positions for coord in pos]\n",
    "    indices_2 = (f2, w2) + tuple(enemy_positions_flat)\n",
    "    e3=optimized_relative_positions(\n",
    "        (maze_rows, maze_cols), (x,(y+1)%maze_rows), og_enemy_positions, grid_size=grid_size\n",
    "    )\n",
    "    f3 = int(reward_maze[x][(y+1)%maze_rows] == 2)\n",
    "    w3 = int(reward_maze[x][(y+1)%maze_rows] == 1)\n",
    "    max_enemies_in_local_grid = len(e3)\n",
    "    e3.sort()\n",
    "    padded_enemy_positions = e3[:max_enemies_in_local_grid]\n",
    "    num_missing = max_enemies_in_local_grid - len(padded_enemy_positions)\n",
    "    padded_enemy_positions.extend([(-1, -1)] * num_missing)\n",
    "    enemy_positions_flat = [coord for pos in padded_enemy_positions for coord in pos]\n",
    "    indices_3 = (f3, w3) + tuple(enemy_positions_flat)\n",
    "    e4=optimized_relative_positions(\n",
    "        (maze_rows, maze_cols), (x,(y-1)%maze_rows), og_enemy_positions, grid_size=grid_size\n",
    "    )\n",
    "    f4 = int(reward_maze[x][(y-1)%maze_rows] == 2)\n",
    "    w4 = int(reward_maze[x][(y-1)%maze_rows] == 1)\n",
    "    max_enemies_in_local_grid = len(e4)\n",
    "    e4.sort()\n",
    "    padded_enemy_positions = e4[:max_enemies_in_local_grid]\n",
    "    num_missing = max_enemies_in_local_grid - len(padded_enemy_positions)\n",
    "    padded_enemy_positions.extend([(-1, -1)] * num_missing)\n",
    "    enemy_positions_flat = [coord for pos in padded_enemy_positions for coord in pos]\n",
    "    indices_4 = (f4, w4) + tuple(enemy_positions_flat)\n",
    "    val_1 = estimated_value_grid.get(indices_1, 0)\n",
    "    val_2 = estimated_value_grid.get(indices_2, 0)\n",
    "    val_3 = estimated_value_grid.get(indices_3, 0)\n",
    "    val_4 = estimated_value_grid.get(indices_4, 0)\n",
    "\n",
    "    moves = [\n",
    "        (val_1, (1, 0)),   \n",
    "        (val_2, (-1, 0)),  \n",
    "        (val_3, (0, 1)),   \n",
    "        (val_4, (0, -1)),  \n",
    "    ]\n",
    "\n",
    "    # Pick the move with the greatest value\n",
    "    best_val, best_move = max(moves, key=lambda x: x[0])\n",
    "    policy[old_indices_s]=best_move\n",
    "\n",
    "    return policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SARSA_Update(policy, prev_player_pos,new_player_pos,estimated_value_grid, enemies, reward_maze, visited_empty_spaces,grid_size=5,learning_rate=0.1, discount=0.9):\n",
    "    maze_rows, maze_cols = len(reward_maze),len(reward_maze[0])\n",
    "    og_enemy_positions = [enemy[\"pos\"] for enemy in enemies]\n",
    "    new_elative_enemy_positions = optimized_relative_positions(\n",
    "        (maze_rows, maze_cols), new_player_pos, og_enemy_positions, grid_size=grid_size\n",
    "    )\n",
    "    old_relative_enemy_positions = optimized_relative_positions(\n",
    "        (maze_rows, maze_cols), prev_player_pos, og_enemy_positions, grid_size=grid_size\n",
    "    )\n",
    "    old_food = int(reward_maze[prev_player_pos[0]][prev_player_pos[1]] == 2)\n",
    "    old_wall = int(reward_maze[prev_player_pos[0]][prev_player_pos[1]] == 1)\n",
    "\n",
    "    new_food = int(reward_maze[new_player_pos[0]][new_player_pos[1]] == 2)\n",
    "    new_wall = int(reward_maze[new_player_pos[0]][new_player_pos[1]] == 1)\n",
    "\n",
    "    max_enemies_in_local_grid = len(old_relative_enemy_positions)\n",
    "    old_relative_enemy_positions.sort()\n",
    "    old_padded_enemy_positions = old_relative_enemy_positions[:max_enemies_in_local_grid]\n",
    "    num_missing = max_enemies_in_local_grid - len(old_padded_enemy_positions)\n",
    "    old_padded_enemy_positions.extend([(-1, -1)] * num_missing) \n",
    "    old_enemy_positions_flat = [coord for pos in old_padded_enemy_positions for coord in pos]\n",
    "\n",
    "\n",
    "    max_enemies_in_local_grid = len(new_elative_enemy_positions)\n",
    "    new_elative_enemy_positions.sort()\n",
    "    new_padded_enemy_positions = new_elative_enemy_positions[:max_enemies_in_local_grid]\n",
    "    num_missing = max_enemies_in_local_grid - len(new_padded_enemy_positions)\n",
    "    new_padded_enemy_positions.extend([(-1, -1)] * num_missing)  \n",
    "    new_enemy_positions_flat = [coord for pos in new_padded_enemy_positions for coord in pos]\n",
    "\n",
    "\n",
    "    old_indices_s = (old_food, old_wall) + tuple(old_enemy_positions_flat)\n",
    "    new_indices_s = (new_food, new_wall) + tuple(new_enemy_positions_flat)\n",
    "    \n",
    "    QS1A1=estimated_value_grid.get(new_indices_s)\n",
    "    if check_collision(new_player_pos, enemies):\n",
    "        R1 = -99999 # Collision with enemy\n",
    "        print(\"Collision Detected\")\n",
    "        visited_empty_spaces=0\n",
    "    elif new_wall:\n",
    "        visited_empty_spaces=0\n",
    "        R1 = -10 # Attempted to move into a wall\n",
    "    elif new_food:  # Food\n",
    "        visited_empty_spaces=0\n",
    "        R1 = 1\n",
    "    else:\n",
    "        R1 = -1 # Default penalty for empty space\n",
    "        visited_empty_spaces+=1\n",
    "    QSA=estimated_value_grid.get(old_indices_s)\n",
    "    if QSA is None:\n",
    "        QSA=0\n",
    "    if QS1A1 is None:\n",
    "        QS1A1=0\n",
    "    print(QSA,learning_rate,R1,discount,QS1A1)\n",
    "    estimated_value_grid[old_indices_s]= QSA + learning_rate*(R1+discount*QS1A1)-QSA\n",
    "    policy=update_policy(old_indices_s,policy, prev_player_pos,estimated_value_grid, og_enemy_positions, reward_maze)\n",
    "    return estimated_value_grid,policy,visited_empty_spaces\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_positions(maze, num_enemies):\n",
    "    maze_rows, maze_cols = len(maze), len(maze[0])\n",
    "\n",
    "    # Find all possible positions (excluding walls)\n",
    "    possible_positions = [(x, y) for x in range(maze_rows) for y in range(maze_cols) if maze[x][y] != 1]\n",
    "\n",
    "    # Randomly select a position for the player\n",
    "    player_pos = random.choice(possible_positions)\n",
    "\n",
    "    # Remove player's position from possible positions\n",
    "    possible_positions.remove(player_pos)\n",
    "\n",
    "    enemies = []\n",
    "    for _ in range(num_enemies):\n",
    "        if not possible_positions:\n",
    "            break  # No more positions available\n",
    "        enemy_pos = random.choice(possible_positions)\n",
    "        enemies.append({\"pos\": enemy_pos, \"target\": None})\n",
    "        possible_positions.remove(enemy_pos)\n",
    "\n",
    "    return player_pos, enemies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxt=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game:\n",
    "    def __init__(self, maze, player_pos, enemies, score=0, timeout=maxt):\n",
    "        self.maze = maze\n",
    "        self.player_pos = player_pos\n",
    "        self.enemies = enemies\n",
    "        self.score = score\n",
    "        self.timeout = timeout\n",
    "        self.state_action_log = []\n",
    "        self.running = True  # Indicates if the game is still running\n",
    "        self.visited_empty_spaces = 0\n",
    "\n",
    "    def restart_game(self):\n",
    "        self.maze = create_maze(ROWS, COLS)\n",
    "        self.player_pos, self.enemies = initialize_positions(self.maze, num_enemies)\n",
    "        self.score = 0\n",
    "        self.timeout = maxt\n",
    "        self.state_action_log = []\n",
    "        self.running = True\n",
    "        self.visited_empty_spaces=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neeed to handle when food is taken it automaticly changes it state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.init()\n",
    "print(\"RRUN\")\n",
    "global policy, maxt,estimated_value_grid\n",
    "maxt = 50\n",
    "num_games = 6  # Number of games to run\n",
    "games = []\n",
    "for _ in range(num_games):\n",
    "    maze = create_maze(ROWS, COLS)\n",
    "    player_pos, enemies = initialize_positions(maze, num_enemies)\n",
    "    game = Game(maze, player_pos, enemies, score=0, timeout=maxt)\n",
    "    games.append(game)\n",
    "\n",
    "clock = pygame.time.Clock()\n",
    "running = True\n",
    "while running:\n",
    "    # Handle events (e.g., quitting the game)\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "\n",
    "    # For each game instance, update its state\n",
    "    all_games_ready_for_update = True\n",
    "    for game in games:\n",
    "        if not game.running:\n",
    "            continue  # Skip if game is not running\n",
    "        \n",
    "        if game.timeout == 0:\n",
    "            # Check if all games have reached the timeout\n",
    "            pass  # We'll handle synchronization after this loop\n",
    "        else:\n",
    "            all_games_ready_for_update = False\n",
    "            current_state = game.player_pos\n",
    "            action = Next_action(current_state, policy, game.enemies, game.maze, grid_size=5)\n",
    "            game.timeout -= 1\n",
    "            new_player_pos = move_entity(game.player_pos, action)\n",
    "            move_enemies(game.enemies, game.maze)\n",
    "            estimated_value_grid,policy,game.visited_empty_spaces=SARSA_Update(policy, current_state,new_player_pos,estimated_value_grid, game.enemies, game.maze,game.visited_empty_spaces, grid_size=5,learning_rate=0.1, discount=0.9)\n",
    "            if is_valid_move(new_player_pos, game.maze):\n",
    "                if game.maze[new_player_pos[0]][new_player_pos[1]] == 2:  # Collect food\n",
    "                    game.score += 1\n",
    "                    game.maze[new_player_pos[0]][new_player_pos[1]] = 0\n",
    "                game.player_pos = new_player_pos\n",
    "            print(game.visited_empty_spaces)\n",
    "            \n",
    "            # Check for collisions\n",
    "            for enemy in game.enemies or game.visited_empty_spaces>=5:\n",
    "                if enemy[\"pos\"] == game.player_pos or check_collision(game.player_pos, game.enemies):\n",
    "                    print(\"Game Over! Restarting...\")\n",
    "                    game.running = False  # Mark the game for update\n",
    "\n",
    "            # Check if all food is collected\n",
    "            if all(game.maze[row][col] != 2 for row in range(ROWS) for col in range(COLS)):\n",
    "                print(\"You Win! Restarting...\")\n",
    "                game.running = False  # Mark the game for update\n",
    "\n",
    "            \n",
    "\n",
    "    # Synchronize updates\n",
    "    if all_games_ready_for_update or all(not game.running for game in games):\n",
    "        # Run Next_Cycle for each game\n",
    "        for game in games:\n",
    "            game.restart_game()\n",
    "            game.running = True  # Reset the running flag\n",
    "        if maxt < 10000:\n",
    "            maxt += 10\n",
    "\n",
    "    # Draw all games\n",
    "    draw_all_games(games)\n",
    "\n",
    "    pygame.display.flip()\n",
    "    clock.tick(FPS)\n",
    "pygame.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
